{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5c2bf0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe==0.10.31 in c:\\users\\preda\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages (0.10.31)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\preda\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages (4.13.0.90)\n",
      "Requirement already satisfied: pycaw in c:\\users\\preda\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages (20251023)\n",
      "Requirement already satisfied: comtypes in c:\\users\\preda\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages (1.4.15)\n",
      "Requirement already satisfied: numpy in c:\\users\\preda\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: absl-py~=2.3 in c:\\users\\preda\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages (from mediapipe==0.10.31) (2.3.1)\n",
      "Requirement already satisfied: sounddevice~=0.5 in c:\\users\\preda\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages (from mediapipe==0.10.31) (0.5.4)\n",
      "Requirement already satisfied: flatbuffers~=25.9 in c:\\users\\preda\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages (from mediapipe==0.10.31) (25.12.19)\n",
      "Requirement already satisfied: psutil in c:\\users\\preda\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages (from pycaw) (7.2.1)\n",
      "Requirement already satisfied: cffi in c:\\users\\preda\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages (from sounddevice~=0.5->mediapipe==0.10.31) (2.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\preda\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages (from cffi->sounddevice~=0.5->mediapipe==0.10.31) (3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies. \n",
    "# We need specific versions to ensure stability.\n",
    "!pip install mediapipe==0.10.31 opencv-python pycaw comtypes numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "963beaf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model already exists.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "\n",
    "# Download the specific Hand Landmarker model for 0.10.31\n",
    "url = \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n",
    "model_path = \"hand_landmarker.task\"\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    urllib.request.urlretrieve(url, model_path)\n",
    "    print(\"Model downloaded successfully.\")\n",
    "else:\n",
    "    print(\"Model already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6d463a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "from ctypes import cast, POINTER\n",
    "from comtypes import CLSCTX_ALL\n",
    "# We import the raw interface definitions\n",
    "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\n",
    "from comtypes import CoCreateInstance, GUID, CLSCTX_ALL\n",
    "from ctypes import cast, POINTER\n",
    "from pycaw.pycaw import IAudioEndpointVolume, IMMDeviceEnumerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98ba2d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# CONSTANTS for Windows Audio (Core Audio APIs)\n",
    "# We manually define the Class ID for the Device Enumerator\n",
    "CLSID_MMDeviceEnumerator = GUID('{BCDE0395-E52F-467C-8E3D-C4579291692E}')\n",
    "EDataFlow_eRender = 0      # Audio Output\n",
    "ERole_eMultimedia = 1      # Multimedia Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "814ba082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create the Device Enumerator directly\n",
    "device_enumerator = CoCreateInstance(\n",
    "    CLSID_MMDeviceEnumerator,\n",
    "    IMMDeviceEnumerator,\n",
    "    CLSCTX_ALL\n",
    ")\n",
    "\n",
    "# 2. Get the Default Audio Endpoint (Speakers)\n",
    "# We bypass \"GetSpeakers()\" and ask for the Render device directly\n",
    "speakers = device_enumerator.GetDefaultAudioEndpoint(EDataFlow_eRender, ERole_eMultimedia)\n",
    "\n",
    "# 3. Activate the Interface\n",
    "# This is the line that was failing before. Now we are calling it on the raw COM object.\n",
    "interface = speakers.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ab56be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success. Volume Range: -65.25 dB to 0.0 dB\n"
     ]
    }
   ],
   "source": [
    "# Cast the interface to a pointer we can use\n",
    "volume = cast(interface, POINTER(IAudioEndpointVolume))\n",
    "\n",
    "# Get the volume range (dB)\n",
    "vol_range = volume.GetVolumeRange()\n",
    "min_vol = vol_range[0]\n",
    "max_vol = vol_range[1]\n",
    "\n",
    "print(f\"Success. Volume Range: {min_vol} dB to {max_vol} dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f78044d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the HandLandmarker options\n",
    "BaseOptions = mp.tasks.BaseOptions\n",
    "HandLandmarker = mp.tasks.vision.HandLandmarker\n",
    "HandLandmarkerOptions = mp.tasks.vision.HandLandmarkerOptions\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "\n",
    "# Configure options for Live Video\n",
    "options = HandLandmarkerOptions(\n",
    "    base_options=BaseOptions(model_asset_path='hand_landmarker.task'),\n",
    "    running_mode=VisionRunningMode.VIDEO,\n",
    "    num_hands=1,\n",
    "    min_hand_detection_confidence=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1e1bed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_range(value, in_min, in_max, out_min, out_max):\n",
    "    \"\"\"\n",
    "    Linearly maps a value from input range to output range.\n",
    "    \"\"\"\n",
    "    return (value - in_min) * (out_max - out_min) / (in_max - in_min) + out_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "000aaf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Create the landmarker instance\n",
    "landmarker = HandLandmarker.create_from_options(options)\n",
    "\n",
    "# Track time for timestamps (required by Tasks API)\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a54b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success: break\n",
    "\n",
    "    # Convert to RGB for MediaPipe\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)\n",
    "\n",
    "    # Calculate timestamp in ms\n",
    "    timestamp_ms = int((time.time() - start_time) * 1000)\n",
    "    \n",
    "    # Detect Async (Video Mode)\n",
    "    detection_result = landmarker.detect_for_video(mp_image, timestamp_ms)\n",
    "\n",
    "\n",
    "    if detection_result.hand_landmarks:\n",
    "        hand = detection_result.hand_landmarks[0]\n",
    "        \n",
    "        # Get Thumb (4) and Index (8) coordinates\n",
    "        # Coordinates are normalized (0.0 to 1.0), so multiply by width/height\n",
    "        h, w, _ = frame.shape\n",
    "        x1, y1 = int(hand[4].x * w), int(hand[4].y * h)\n",
    "        x2, y2 = int(hand[8].x * w), int(hand[8].y * h)\n",
    "\n",
    "        # Draw visuals\n",
    "        cv2.circle(frame, (x1, y1), 10, (255, 0, 0), cv2.FILLED)\n",
    "        cv2.circle(frame, (x2, y2), 10, (255, 0, 0), cv2.FILLED)\n",
    "        cv2.line(frame, (x1, y1), (x2, y2), (255, 0, 0), 3)\n",
    "      \n",
    "        # Calculate distance\n",
    "        length = np.hypot(x2 - x1, y2 - y1)\n",
    "\n",
    "        # Mute if fingers are pinched (distance < 25)\n",
    "        if length < 25:\n",
    "            volume.SetMasterVolumeLevel(min_vol, None)\n",
    "            cv2.putText(frame, \"MUTED\", (50, 50), cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 255), 2)\n",
    "        else:\n",
    "            # Map distance (approx 25px - 200px) to volume range\n",
    "            # We use np.interp for safe interpolation (clamps values)\n",
    "            target_vol = np.interp(length, [25, 200], [min_vol, max_vol])\n",
    "            volume.SetMasterVolumeLevel(target_vol, None)\n",
    "\n",
    "    # Show frame\n",
    "    cv2.imshow('Volume Control', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3fd2bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
