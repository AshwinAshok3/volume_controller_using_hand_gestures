{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82d748f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\preda\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages (0.10.31)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\preda\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages (4.13.0.90)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\preda\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages (3.10.8)\n",
      "Requirement already satisfied: flatbuffers~=25.9 in c:\\users\\preda\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages (from mediapipe) (25.12.19)\n",
      "Requirement already satisfied: absl-py~=2.3 in c:\\users\\preda\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages (from mediapipe) (2.3.1)\n",
      "Requirement already satisfied: sounddevice~=0.5 in c:\\users\\preda\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages (from mediapipe) (0.5.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\preda\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages (from mediapipe) (2.2.6)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\preda\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\preda\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages (from matplotlib) (26.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\preda\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\preda\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\preda\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\preda\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages (from matplotlib) (3.3.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\preda\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages (from matplotlib) (12.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\preda\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\preda\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: cffi in c:\\users\\preda\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages (from sounddevice~=0.5->mediapipe) (2.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\preda\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages (from cffi->sounddevice~=0.5->mediapipe) (3.0)\n",
      "‚úÖ Installation Complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 25.3\n",
      "[notice] To update, run: c:\\Users\\preda\\.pyenv\\pyenv-win\\versions\\3.10.7\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# CELL 1: Install Libraries\n",
    "import sys\n",
    "\n",
    "# We use 'pip' (Python's app store) to install MediaPipe\n",
    "!{sys.executable} -m pip install mediapipe opencv-python matplotlib\n",
    "\n",
    "print(\"‚úÖ Installation Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1f8b6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ready. Using MediaPipe Version: 0.10.31\n"
     ]
    }
   ],
   "source": [
    "# CELL 2: Imports\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "# Define the \"Tasks\" library (The new v0.10.31 way of doing things)\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision, text, audio\n",
    "\n",
    "print(f\"‚úÖ Ready. Using MediaPipe Version: {mp.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "280afc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Downloading Text Brain...\n",
      "‚úÖ Text Model Downloaded.\n"
     ]
    }
   ],
   "source": [
    "# CELL 3: Download Text Model\n",
    "text_model_url = \"https://storage.googleapis.com/mediapipe-models/text_classifier/bert_classifier/float32/1/bert_classifier.tflite\"\n",
    "text_model_file = \"bert_classifier.tflite\"\n",
    "\n",
    "if not os.path.exists(text_model_file):\n",
    "    print(\"üì• Downloading Text Brain...\")\n",
    "    urllib.request.urlretrieve(text_model_url, text_model_file)\n",
    "    print(\"‚úÖ Text Model Downloaded.\")\n",
    "else:\n",
    "    print(\"‚ö° Text Model already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f95d90c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° Vision Model already exists.\n"
     ]
    }
   ],
   "source": [
    "# CELL 4: Download Vision Model\n",
    "vision_model_url = \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\"\n",
    "vision_model_file = \"face_landmarker.task\"\n",
    "\n",
    "if not os.path.exists(vision_model_file):\n",
    "    print(\"üì• Downloading Vision Brain...\")\n",
    "    urllib.request.urlretrieve(vision_model_url, vision_model_file)\n",
    "    print(\"‚úÖ Vision Model Downloaded.\")\n",
    "else:\n",
    "    print(\"‚ö° Vision Model already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7afce247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° Audio Model already exists.\n"
     ]
    }
   ],
   "source": [
    "# CELL 5: Download Audio Model\n",
    "audio_model_url = \"https://storage.googleapis.com/mediapipe-models/audio_classifier/yamnet/float32/1/yamnet.tflite\"\n",
    "audio_model_file = \"yamnet.tflite\"\n",
    "\n",
    "if not os.path.exists(audio_model_file):\n",
    "    print(\"üì• Downloading Audio Brain...\")\n",
    "    urllib.request.urlretrieve(audio_model_url, audio_model_file)\n",
    "    print(\"‚úÖ Audio Model Downloaded.\")\n",
    "else:\n",
    "    print(\"‚ö° Audio Model already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff951d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Text Classifier is Awake.\n"
     ]
    }
   ],
   "source": [
    "# CELL 6: Setup Text AI\n",
    "base_options = python.BaseOptions(model_asset_path=text_model_file)\n",
    "options = text.TextClassifierOptions(base_options=base_options)\n",
    "\n",
    "# Create the tool\n",
    "text_classifier = text.TextClassifier.create_from_options(options)\n",
    "print(\"‚úÖ Text Classifier is Awake.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f278b4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 'I am feeling nice for now, atleast'\n",
      "AI thinks this is: positive (Score: 0.99)\n"
     ]
    }
   ],
   "source": [
    "# CELL 7: Test Happy Input\n",
    "my_text = \"I am feeling nice for now, atleast\"\n",
    "classification = text_classifier.classify(my_text)\n",
    "\n",
    "# The result is a list. Category 0 is usually 'negative', 1 is 'positive'\n",
    "# But let's look at the label names directly.\n",
    "top_result = classification.classifications[0].categories[0]\n",
    "\n",
    "print(f\"Input: '{my_text}'\")\n",
    "print(f\"AI thinks this is: {top_result.category_name} (Score: {top_result.score:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a59390d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 'I am feeling very down and lonely.'\n",
      "AI thinks this is: negative (Score: 0.97)\n"
     ]
    }
   ],
   "source": [
    "# CELL 8: Test Sad Input\n",
    "sad_text = \"I am feeling very down and lonely.\"\n",
    "classification = text_classifier.classify(sad_text)\n",
    "top_result = classification.classifications[0].categories[0]\n",
    "\n",
    "print(f\"Input: '{sad_text}'\")\n",
    "print(f\"AI thinks this is: {top_result.category_name} (Score: {top_result.score:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf134c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Face AI is Awake.\n"
     ]
    }
   ],
   "source": [
    "# CELL 9: Setup Vision AI\n",
    "base_options = python.BaseOptions(model_asset_path=vision_model_file)\n",
    "options = vision.FaceLandmarkerOptions(\n",
    "    base_options=base_options,\n",
    "    output_face_blendshapes=True, # <--- THIS allows us to see smiles!\n",
    "    running_mode=vision.RunningMode.VIDEO,\n",
    "    num_faces=1)\n",
    "\n",
    "face_landmarker = vision.FaceLandmarker.create_from_options(options)\n",
    "print(\"‚úÖ Face AI is Awake.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c70649d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Camera is ready.\n"
     ]
    }
   ],
   "source": [
    "# CELL 10: Camera Access\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "\n",
    "if cap.isOpened():\n",
    "    print(\"‚úÖ Camera is ready.\")\n",
    "else:\n",
    "    print(\"‚ùå Camera failed. Check your settings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9228ab81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Controls: Smile to be Happy. Press 'q' to stop.\n"
     ]
    }
   ],
   "source": [
    "# CELL 11: Real-time Emotion Detector\n",
    "import time\n",
    "\n",
    "print(\"Controls: Smile to be Happy. Press 'q' to stop.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "\n",
    "    # Convert to MediaPipe format\n",
    "    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    timestamp = int(time.time() * 1000)\n",
    "\n",
    "    # Detect\n",
    "    result = face_landmarker.detect_for_video(mp_image, timestamp)\n",
    "\n",
    "    # LOGIC: Check for Smile\n",
    "    status = \"Neutral / Sad\"\n",
    "    color = (0, 0, 255) # Red\n",
    "\n",
    "    if result.face_blendshapes:\n",
    "        # Access the first face detected\n",
    "        shapes = result.face_blendshapes[0]\n",
    "        \n",
    "        # Blendshape #52 is usually 'mouthSmileLeft' and #53 is 'mouthSmileRight'\n",
    "        # But looking up by name is safer:\n",
    "        smile_score = 0\n",
    "        for shape in shapes:\n",
    "            if shape.category_name == 'mouthSmileLeft' or shape.category_name == 'mouthSmileRight':\n",
    "                smile_score += shape.score\n",
    "\n",
    "        # Average the two sides\n",
    "        smile_score /= 2\n",
    "\n",
    "        if smile_score > 0.5:\n",
    "            status = \"HAPPY / SMILING\"\n",
    "            color = (0, 255, 0) # Green\n",
    "\n",
    "    cv2.putText(frame, f\"Emotion: {status}\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "    cv2.imshow('Emotion Detector', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "99e346d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Audio AI is Awake and ready to listen.\n"
     ]
    }
   ],
   "source": [
    "# CELL 12: Setup Audio AI\n",
    "from mediapipe.tasks.python.audio.core import audio_record\n",
    "from mediapipe.tasks.python.components.containers import audio_data as audio_data_module\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import audio\n",
    "\n",
    "# Configure the model\n",
    "base_options = python.BaseOptions(model_asset_path=\"yamnet.tflite\")\n",
    "options = audio.AudioClassifierOptions(\n",
    "    base_options=base_options,\n",
    "    max_results=3)\n",
    "\n",
    "# Create the tool\n",
    "audio_classifier = audio.AudioClassifier.create_from_options(options)\n",
    "print(\"‚úÖ Audio AI is Awake and ready to listen.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a76fd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéß Scanning Audio Devices...\n",
      "   0 Microsoft Sound Mapper - Input, MME (2 in, 0 out)\n",
      ">  1 Headset Microphone (Oculus Virt, MME (1 in, 0 out)\n",
      "   2 Microphone Array (Intel¬Æ Smart , MME (4 in, 0 out)\n",
      "   3 Microsoft Sound Mapper - Output, MME (0 in, 2 out)\n",
      "<  4 Speakers (Realtek(R) Audio), MME (0 in, 2 out)\n",
      "   5 Headphones (Oculus Virtual Audi, MME (0 in, 2 out)\n",
      "   6 Primary Sound Capture Driver, Windows DirectSound (2 in, 0 out)\n",
      "   7 Headset Microphone (Oculus Virtual Audio Device), Windows DirectSound (1 in, 0 out)\n",
      "   8 Microphone Array (Intel¬Æ Smart Sound Technology for Digital Microphones), Windows DirectSound (4 in, 0 out)\n",
      "   9 Primary Sound Driver, Windows DirectSound (0 in, 2 out)\n",
      "  10 Speakers (Realtek(R) Audio), Windows DirectSound (0 in, 2 out)\n",
      "  11 Headphones (Oculus Virtual Audio Device), Windows DirectSound (0 in, 2 out)\n",
      "  12 Speakers (Realtek(R) Audio), Windows WASAPI (0 in, 2 out)\n",
      "  13 Headphones (Oculus Virtual Audio Device), Windows WASAPI (0 in, 2 out)\n",
      "  14 Headset Microphone (Oculus Virtual Audio Device), Windows WASAPI (1 in, 0 out)\n",
      "  15 Microphone Array (Intel¬Æ Smart Sound Technology for Digital Microphones), Windows WASAPI (2 in, 0 out)\n",
      "  16 Output 1 (OCULUSVAD Wave Speaker Headphone), Windows WDM-KS (0 in, 2 out)\n",
      "  17 Output 2 (OCULUSVAD Wave Speaker Headphone), Windows WDM-KS (0 in, 2 out)\n",
      "  18 Input (OCULUSVAD Wave Speaker Headphone), Windows WDM-KS (2 in, 0 out)\n",
      "  19 Headset Microphone (OCULUSVAD Wave Microphone Headphone), Windows WDM-KS (1 in, 0 out)\n",
      "  20 Microphone Array 1 (), Windows WDM-KS (2 in, 0 out)\n",
      "  21 Microphone Array 2 (), Windows WDM-KS (2 in, 0 out)\n",
      "  22 Microphone Array 3 (), Windows WDM-KS (4 in, 0 out)\n",
      "  23 Stereo Mix (Realtek HD Audio Stereo input), Windows WDM-KS (2 in, 0 out)\n",
      "  24 Headphones 1 (Realtek HD Audio 2nd output with SST), Windows WDM-KS (0 in, 2 out)\n",
      "  25 Headphones 2 (Realtek HD Audio 2nd output with SST), Windows WDM-KS (0 in, 2 out)\n",
      "  26 PC Speaker (Realtek HD Audio 2nd output with SST), Windows WDM-KS (2 in, 0 out)\n",
      "  27 Speakers 1 (Realtek HD Audio output with SST), Windows WDM-KS (0 in, 2 out)\n",
      "  28 Speakers 2 (Realtek HD Audio output with SST), Windows WDM-KS (0 in, 2 out)\n",
      "  29 PC Speaker (Realtek HD Audio output with SST), Windows WDM-KS (2 in, 0 out)\n",
      "  30 Microphone (Realtek HD Audio Mic input), Windows WDM-KS (2 in, 0 out)\n",
      "\n",
      "------------------------------------------------\n",
      "üëâ LOOK AT THE LIST ABOVE.\n",
      "Find the number (Index) next to your actual Microphone.\n",
      "Ignore 'Microsoft Sound Mapper' or 'Primary Sound Capture'.\n",
      "Look for hardware names like 'Microphone Array (Realtek)' or 'Headset'.\n"
     ]
    }
   ],
   "source": [
    "# CELL: Find My Microphone\n",
    "import sounddevice as sd\n",
    "\n",
    "print(\"üéß Scanning Audio Devices...\")\n",
    "print(sd.query_devices())\n",
    "\n",
    "print(\"\\n------------------------------------------------\")\n",
    "print(\"üëâ LOOK AT THE LIST ABOVE.\")\n",
    "print(\"Find the number (Index) next to your actual Microphone.\")\n",
    "print(\"Ignore 'Microsoft Sound Mapper' or 'Primary Sound Capture'.\")\n",
    "print(\"Look for hardware names like 'Microphone Array (Realtek)' or 'Headset'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "205d6007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé§ Recording for 5 seconds using Device 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored from cffi callback <function _StreamBase.__init__.<locals>.finished_callback_wrapper at 0x000002743AB0FF40>:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\preda\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages\\sounddevice.py\", line 940, in finished_callback_wrapper\n",
      "    return finished_callback()\n",
      "  File \"c:\\Users\\preda\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages\\sounddevice.py\", line 2652, in finished_callback\n",
      "    del self.data\n",
      "AttributeError: data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Volume captured: 0.1018\n",
      "‚úÖ Success! Audio captured.\n"
     ]
    }
   ],
   "source": [
    "# CELL 13 (FIXED): Recorder with Device Selector\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# CHANGE THIS NUMBER to the index you found in Step 1!\n",
    "# If you are not sure, try 1, then 2, then 3.\n",
    "MY_MIC_INDEX = 2\n",
    "# ---------------------\n",
    "\n",
    "def record_audio(duration=5, sample_rate=16000, device_id=MY_MIC_INDEX):\n",
    "    print(f\"üé§ Recording for {duration} seconds using Device {device_id}...\")\n",
    "    \n",
    "    try:\n",
    "        # We add 'blocking=True' and explicit device selection\n",
    "        recording = sd.rec(int(duration * sample_rate), \n",
    "                           samplerate=sample_rate, \n",
    "                           channels=1, \n",
    "                           dtype='float32',\n",
    "                           device=device_id, \n",
    "                           blocking=True)\n",
    "        \n",
    "        # Check if we actually got sound\n",
    "        vol = np.max(np.abs(recording))\n",
    "        print(f\"üìä Volume captured: {vol:.4f}\")\n",
    "        \n",
    "        if vol == 0.0:\n",
    "            print(\"‚ùå ERROR: Still hearing Silence (0.0). Try a different Device Index!\")\n",
    "        else:\n",
    "            print(\"‚úÖ Success! Audio captured.\")\n",
    "            \n",
    "        return recording\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Device Failed: {e}\")\n",
    "        return np.zeros((int(duration*sample_rate), 1))\n",
    "\n",
    "# Test it immediately\n",
    "test_audio = record_audio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "209a8f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé§ Recording for 5 seconds using Device 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored from cffi callback <function _StreamBase.__init__.<locals>.finished_callback_wrapper at 0x000002743AB94D30>:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\preda\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages\\sounddevice.py\", line 940, in finished_callback_wrapper\n",
      "    return finished_callback()\n",
      "  File \"c:\\Users\\preda\\.pyenv\\pyenv-win\\versions\\3.10.7\\lib\\site-packages\\sounddevice.py\", line 2652, in finished_callback\n",
      "    del self.data\n",
      "AttributeError: data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Volume captured: 0.1601\n",
      "‚úÖ Success! Audio captured.\n",
      "üìä Volume Level: 0.1601\n",
      "\n",
      "üèÜ Top 3 Guesses:\n",
      "------------------------------\n",
      "1. Grunt (Confidence: 0.41)\n",
      "2. Roar (Confidence: 0.26)\n",
      "3. Roaring cats (lions, tigers) (Confidence: 0.26)\n"
     ]
    }
   ],
   "source": [
    "# CELL 14 (DEBUG MODE): Audio Analysis with \"Top 3\" & Volume Check\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    # 1. Record Audio\n",
    "    raw_audio = record_audio() # Uses the function from Cell 13\n",
    "    \n",
    "    # --- DEBUG 1: VOLUME CHECK ---\n",
    "    # We check how loud the sound was (0.0 to 1.0)\n",
    "    volume = np.max(np.abs(raw_audio))\n",
    "    print(f\"üìä Volume Level: {volume:.4f}\")\n",
    "    \n",
    "    if volume < 0.01:\n",
    "        print(\"‚ö†Ô∏è WARNING: Audio is too quiet! Move closer to the mic.\")\n",
    "    # -----------------------------\n",
    "\n",
    "    # 2. Prepare Data\n",
    "    raw_audio = raw_audio.squeeze()\n",
    "    mp_audio = audio_data_module.AudioData.create_from_array(\n",
    "        raw_audio.astype(float), 16000)\n",
    "\n",
    "    # 3. Classify\n",
    "    results = audio_classifier.classify(mp_audio)\n",
    "    \n",
    "    # 4. Show Top 3 Results (To see what's hiding)\n",
    "    if results:\n",
    "        categories = results[0].classifications[0].categories\n",
    "        \n",
    "        print(\"\\nüèÜ Top 3 Guesses:\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        for i, category in enumerate(categories):\n",
    "            print(f\"{i+1}. {category.category_name} (Confidence: {category.score:.2f})\")\n",
    "            \n",
    "            # Simple Emotion Logic based on the specific category\n",
    "            if category.category_name in [\"Laughter\", \"Giggle\", \"Snicker\"]:\n",
    "                print(f\"   >>> EMOTION DETECTED: HAPPY üòä (Rank {i+1})\")\n",
    "            elif category.category_name in [\"Crying, sobbing\", \"Whimper\"]:\n",
    "                print(f\"   >>> EMOTION DETECTED: SAD üò¢ (Rank {i+1})\")\n",
    "                \n",
    "    else:\n",
    "        print(\"No sound detected.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53b51338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéâ COURSE COMPLETE!\n",
      "1. We built a Text AI that knows if you write happy words.\n",
      "2. We built a Vision AI that sees if you smile.\n",
      "3. We built an Audio AI that hears if you laugh.\n",
      "This is Multimodal AI!\n"
     ]
    }
   ],
   "source": [
    "# CELL 15: Conclusion\n",
    "print(\"üéâ COURSE COMPLETE!\")\n",
    "print(\"1. We built a Text AI that knows if you write happy words.\")\n",
    "print(\"2. We built a Vision AI that sees if you smile.\")\n",
    "print(\"3. We built an Audio AI that hears if you laugh.\")\n",
    "print(\"This is Multimodal AI!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
